{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ee362d",
   "metadata": {},
   "source": [
    "# 3D medical images\n",
    "\n",
    "In this notebook we will work on CT scans. This is possible thanks to publicly available dataset such as the ones published on The Cancer Imaging Archive (TCIA). TCIA is a large, publicly accessible database of medical images of cancer patients. It was launched in 2011 by the National Cancer Institute (NCI) in collaboration with several other institutions, including the Foundation for the National Institutes of Health (FNIH) and the National Institutes of Health (NIH). This database contains a vast collection of medical images from a wide range of cancer types and imaging modalities, including MRI, CT, PET, and more. These images are accompanied by detailed clinical and pathological data, making it possible to investigate the relationships between imaging features and disease characteristics, treatment outcomes, and other factors. TCIA is designed to support a wide range of research applications, including cancer diagnosis and treatment planning, drug development, and the development of new imaging techniques and analysis methods. It is an important resource for the cancer research community, and has already been used in numerous research studies and clinical trials.\n",
    "\n",
    "In this notebook we will use part of the data available from [NSCLC-radiomics dataset](https://wiki.cancerimagingarchive.net/display/Public/NSCLC-Radiomics). Which is a collection of medical images and radiomic features from non-small cell lung cancer (NSCLC) patients. The dataset was created by the Cancer Imaging Archive (TCIA) and contains imaging data from 422 NSCLC patients, including CT images and segmentation masks. The images we will work on were previously cropped and subsequently converted into NIfTI file format. The same task was performed on the labeled images (i.e. masks). For this notebook only the lung mask will be available, only one label was selected to reduce the computation time. In the next sections we will load, plot and manipulate both the CT scans and the labeled images. There are several python modules which come to aid for this task, such as: Nibabel, numpy, matplotlib, pyvista, scikit-image, etc.\n",
    "\n",
    "Let's start by downloading the [data](https://baltig.infn.it/postuma/medicalimaging/-/blob/main/MLNN/LungSegmentation/data.zip), unzip the downloaded file and navigate through the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://baltig.infn.it/postuma/medicalimaging/-/raw/main/MLNN/LungSegmentation/data.zip\n",
    "! unzip data.zip\n",
    "! ls data/*/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f272d",
   "metadata": {},
   "source": [
    "We can see that each patient is identified by a number, the number is also a directory contained inside the lctsc directory contained in the data directory. Each patient is represented by 2 NIfTI files (i.e. CT scan and lung mask). We now need a simple way to read the data contained in the dataset, to do this we can use the python **glob** module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713cebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "cases = glob(\"data/lctsc/*\")\n",
    "\n",
    "print(cases)\n",
    "print(len(cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe39767",
   "metadata": {},
   "source": [
    "Since the name of the CT scan and mask are always the same, we can define two variable to store those names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_name = \"ct.nii.gz\"\n",
    "mask_name = \"lung.nii.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094666c1",
   "metadata": {},
   "source": [
    "We can start simple, before plotting the images, take the first case and check the content of the nifty file by pring out its header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858aafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "\n",
    "# first element of the cases array\n",
    "i = 0\n",
    "path_to_img = os.path.join(cases[i],ct_name)\n",
    "\n",
    "# Load the NIfTI image\n",
    "img = nib.load(path_to_img)\n",
    "\n",
    "# Get the image data as a NumPy array\n",
    "data = img.get_fdata()\n",
    "\n",
    "# Print some information about the image\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Data type: {data.dtype}\")\n",
    "print(f\"Voxel size: {img.header.get_zooms()[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c8e57",
   "metadata": {},
   "source": [
    "Now take the first case and plot the image and the mask one on top of the other along the 3 planes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_to_mask = os.path.join(cases[i],mask_name)\n",
    "\n",
    "# Load the NIfTI image\n",
    "mask = nib.load(path_to_mask)\n",
    "\n",
    "# Get the image data as a NumPy array\n",
    "data_m = mask.get_fdata()\n",
    "\n",
    "fig, ax = plt.subplots(2,3,tight_layout=True)\n",
    "\n",
    "fig.suptitle(\"Case {}\".format(cases[i].split(\"/\")[-1]))\n",
    "\n",
    "x_dim = data.shape[0]\n",
    "y_dim = data.shape[1]\n",
    "z_dim = data.shape[2]\n",
    "\n",
    "ax[0,0].set_title(\"YZ Plane\")\n",
    "ax[0,0].imshow(data[x_dim//2], cmap=\"bone\",vmin=-1000, vmax=1000)\n",
    "ax[0,0].axis(\"off\")\n",
    "\n",
    "ax[0,1].set_title(\"XZ Plane\")\n",
    "ax[0,1].imshow(data[:,y_dim//2], cmap=\"bone\",vmin=-1000, vmax=1000)\n",
    "ax[0,1].axis(\"off\")\n",
    "\n",
    "ax[0,2].set_title(\"XY Plane\")\n",
    "ax[0,2].imshow(data[...,z_dim//2], cmap=\"bone\",vmin=-1000, vmax=1000)\n",
    "ax[0,2].axis(\"off\")\n",
    "\n",
    "ax[1,0].imshow(data_m[x_dim//2])\n",
    "ax[1,0].axis(\"off\")\n",
    "\n",
    "ax[1,1].imshow(data_m[:,y_dim//2])\n",
    "ax[1,1].axis(\"off\")\n",
    "\n",
    "ax[1,2].imshow(data_m[...,z_dim//2])\n",
    "ax[1,2].axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c0a61",
   "metadata": {},
   "source": [
    "Other than a mere bidimensional plot, we can also visualise data with a 3D plot by using PyVista. PyVista is an open-source Python library that provides a streamlined interface for 3D visualization and analysis of scientific datasets. It is built on top of the Visualization Toolkit (VTK) and offers a high-level, Pythonic interface that makes it easy to create complex visualizations and perform advanced analysis tasks.\n",
    "\n",
    "PyVista supports a wide range of data types, including structured and unstructured grids, point clouds, and image data, and offers a variety of visualization techniques, such as contouring, slicing, and streamlines. It also provides tools for data analysis, such as mesh smoothing, surface reconstruction, and volume rendering.\n",
    "\n",
    "With this python module we can easily plot the lung mask, could you find a way to plot the CT scan ?\n",
    "\n",
    "To execute the following code box you need to:\n",
    "\n",
    "`!pip install 'jupyterlab>=3' ipywidgets 'pyvista[all,trame]'`\n",
    "\n",
    "and after importing pyvista you may need to:\n",
    "\n",
    "`pv.set_jupyter_backend('trame')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "\n",
    "def get_mask(d,values):\n",
    "    # Create the spatial reference\n",
    "    grid = pv.ImageData()\n",
    "    # Set the grid dimensions: shape\n",
    "    grid.dimensions = np.array(values.shape)\n",
    "    # Edit the spatial reference\n",
    "    grid.origin = values.shape*np.array(d.header.get_zooms())\n",
    "    # The bottom left corner of the data set\n",
    "    grid.spacing = d.header.get_zooms()\n",
    "    # These are the cell sizes along each axis\n",
    "    grid.point_data[\"values\"] = values.flatten(order=\"F\")\n",
    "    return grid.contour()\n",
    "\n",
    "grid = get_mask(mask,data_m)\n",
    "p = pv.Plotter(off_screen=True)\n",
    "p.set_background('white')\n",
    "p.add_mesh(grid, color=\"black\", opacity=0.05, label=\"predicted lung\")\n",
    "p.camera_position = 'xz'\n",
    "p.camera.azimuth = 180\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1321f6ea",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "As you might have noted, our dataset has only 60 images. Compared to the MNIST dataset this is a very small dataset. Anyhow, this is a common problem in medical image artificial neural network training. To overcome this problem we can trick the training process by manipulating the data in a way that the ANN learns to detect variations of the same object. This process is called **data augmentation**.\n",
    "\n",
    "Data augmentation is an essential technique in machine learning for increasing the size of the training dataset and improving the generalization ability of deep learning models. Here are some of the main reasons why data augmentation is important:\n",
    "\n",
    "- **Increased size of training dataset**: Data augmentation can create new samples from the existing ones by applying various transformations such as rotations, flips, shifts, and distortions. This increases the size of the training dataset and reduces the risk of overfitting. With a larger training dataset, deep learning models can learn better features and generalize better to new data.\n",
    "\n",
    "- **Robustness to variations**: Data augmentation can help to make deep learning models more robust to variations in the input data, such as changes in lighting, orientation, scale, and position. By training on a variety of transformed images, deep learning models can learn to recognize patterns and features that are invariant to such variations.\n",
    "\n",
    "- **Reduced dependency on labeled data**: Data augmentation can also help to reduce the dependency on labeled data by generating new samples with different labels. For example, if we have a limited number of labeled images of a certain class, we can generate new images with different orientations and backgrounds to increase the diversity of the training data. This can improve the accuracy of the deep learning model without requiring additional labeled data.\n",
    "\n",
    "- **Improved performance**: Data augmentation has been shown to improve the performance of deep learning models in various computer vision tasks, including image classification, object detection, and segmentation. By incorporating data augmentation into the training pipeline, we can achieve state-of-the-art results with smaller datasets and fewer computational resources.\n",
    "\n",
    "Even if not all of the mentioned data augmentation techniques can be applied to medical images (eg. we cannot change the gray scale intensity since this parameter is connected to the material), data augmentation can help to achieve better results with less effort and resources.\n",
    "\n",
    "In the next example, we perform several types of random augmentations on the image, including rotation, scaling, and adding noise. Finally, we display the original image and the augmented images.\n",
    "\n",
    "Let's see how we can apply some of those techniques to our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "# Load 3D image data\n",
    "\n",
    "# Define transformation parameters\n",
    "angle0 = np.random.uniform(low=-10, high=10)\n",
    "angle1 = np.random.uniform(low=-10, high=10)\n",
    "angle2 = np.random.uniform(low=-10, high=10)\n",
    "scale = np.random.uniform(low=0.8, high=1.2, size=3)\n",
    "shift = np.random.uniform(low=-5, high=5, size=3)\n",
    "sigma = np.random.uniform(low=10, high=100)\n",
    "\n",
    "# Perform affine transformation\n",
    "affine = ndimage.affine_transform(data, np.diag(scale), shift, output_shape=data.shape, order=1, mode='nearest')\n",
    "\n",
    "# Perform rotation\n",
    "rotated = ndimage.rotate(data, angle0, axes=(1,2), reshape=False, order=1, mode='nearest')\n",
    "rotated = ndimage.rotate(rotated, angle1, axes=(1,0), reshape=False, order=1, mode='nearest')\n",
    "rotated = ndimage.rotate(rotated, angle2, axes=(2,0), reshape=False, order=1, mode='nearest')\n",
    "\n",
    "# Perform noise deformation\n",
    "noise = np.random.normal(scale=sigma, size=data.shape)\n",
    "# Add noise to image\n",
    "noisy_image = data + noise\n",
    "\n",
    "# Display the original and augmented images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images = [data,affine,rotated,noisy_image]\n",
    "names  = ['Original','Affine','Rotated','Noisy']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=3, tight_layout=True, figsize=(8,10))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    ax[i,0].set_title(\"YZ Plane {}\".format(names[i]))\n",
    "    ax[i,0].imshow(images[i][x_dim//2], cmap=\"bone\",vmin=-1000, vmax=1000)\n",
    "    ax[i,0].axis(\"off\")\n",
    "\n",
    "    ax[i,1].set_title(\"XZ Plane {}\".format(names[i]))\n",
    "    ax[i,1].imshow(images[i][:,y_dim//2], cmap=\"bone\",vmin=-1000, vmax=1000)\n",
    "    ax[i,1].axis(\"off\")\n",
    "\n",
    "    ax[i,2].set_title(\"XY Plane {}\".format(names[i]))\n",
    "    ax[i,2].imshow(images[i][...,z_dim//2], cmap=\"bone\",vmin=-1000, vmax=1000)\n",
    "    ax[i,2].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d8aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b53872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

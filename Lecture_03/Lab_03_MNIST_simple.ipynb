{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3020,
     "status": "ok",
     "timestamp": 1621431100099,
     "user": {
      "displayName": "Andrea Negri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX3XwAvqoCgDmSTgn9Wv_eAhntGm1Zf112LTgqBQ=s64",
      "userId": "09149238127580964417"
     },
     "user_tz": -120
    },
    "id": "NpunGp0cvOBI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bnWsdfAvOBS"
   },
   "source": [
    "In the lines above we import the keras class mnist, which is a way to download the image digit dataset, and the numpy package.\n",
    "\n",
    "# MNIST dataset\n",
    "\n",
    "Lets have a look at the dataset structure of the dataset. The mnist class has the `load_dat` method which autmatically downlaods the dataset into 2 tuples containing 2 numpy arrays each. The first tuple containing the training images and labels while the latter one containing the test images and labels.\n",
    "\n",
    "Fist thing to do when downloading a new dataset is to check how it is structured. Since the downloaded arrays are numpy we should check it's `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3503,
     "status": "ok",
     "timestamp": 1621346085724,
     "user": {
      "displayName": "Ian Postuma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYeRJeAxy1qvpQ_t5f1YoSP7a1UZO4qbynzAQ8=s64",
      "userId": "15420211039206829163"
     },
     "user_tz": -120
    },
    "id": "ePlr0IwyvOBS",
    "outputId": "dc4e7aca-b744-4d26-aa33-23d78696f5fd"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"train spec\")\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_labels)\n",
    "\n",
    "print(\"\\ntest spec\")\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxHde4J-vOBT"
   },
   "source": [
    "The images are inserted in a *Tensor* of *order* 3, where the first axis is the image number, while the second and third axis are the 2D image with shape 28x28. The label tensor has order 1 and it only contains the corresponding numerical value of the image.\n",
    "\n",
    "To further investigate how the database is composed let us plot an image. This can be performed with the matplolib python package wy using the `imshow` methos of the `pyplot` class, as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1621346087120,
     "user": {
      "displayName": "Ian Postuma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYeRJeAxy1qvpQ_t5f1YoSP7a1UZO4qbynzAQ8=s64",
      "userId": "15420211039206829163"
     },
     "user_tz": -120
    },
    "id": "RB2-4f7dvOBU",
    "outputId": "673300f6-a293-4b44-81d9-4b6f4f0c27c0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_images[4],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJ4Jpzi6vOBU"
   },
   "source": [
    "As you can see, it is very simple to select an image from the `train_images` array. It can be performed by selecting the appropriate image index, in the example we plotted the 5th image of the array (i.e. \\[4\\]).\n",
    "\n",
    "## Simple architecture\n",
    "\n",
    "In this section we will define the simple neural network that we will train for number recognition. From the `Keras` model class we will use the sequential model approach which will automatically connect the tensor layers which are sequentially added to the model. For this network we will use Dense layers (i.e. each node of one layer is connected to each node of the subsequent layer). The layersa are then activated by two functions, relu for the first layer and softmax for the latter one. As you can see, the first layer has the input_shape parameter corresponding to the shape of the images. While the first parameter of the dense layer is the number of nodes of that layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCQq8U6HvOBV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "img_dim = train_images.shape[1] * train_images.shape[2]\n",
    "hidden_neurons = 512\n",
    "output_neurons = 10\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(hidden_neurons, activation=\"tanh\", input_shape=(img_dim,)))\n",
    "network.add(layers.Dense(output_neurons, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_dim)\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxcN5Or7vOBV"
   },
   "source": [
    "One the input and the output of the model are defined, we need to compile the network with the appropriate functions to use during the training.\n",
    "\n",
    "## Model compilation\n",
    "\n",
    "In `Keras`, model compilation is the process of configuring the learning process of a neural network model. This involves specifying the **optimizer**, **loss function**, and **metrics** used to evaluate the performance of the model during training and testing.\n",
    "\n",
    "**The optimizer** determines how the model weights are updated based on the gradients computed during backpropagation. `Keras` provides a variety of optimizers, such as **Adam, SGD, RMSprop, and Adagrad**, which can be customized with different parameters.\n",
    "\n",
    "**The loss function** is used to measure the difference between the predicted output and the actual output. `Keras` supports a range of loss functions, including mean squared error, categorical cross-entropy, binary cross-entropy, and others.\n",
    "\n",
    "**The metrics** are used to evaluate the performance of the model during training and testing. Common metrics in `Keras` include **accuracy**, **precision**, **recall**, **F1-score**, and **mean absolute error**.\n",
    "\n",
    "Once the optimizer, loss function, and metrics are defined, they are compiled together with the model architecture using the `compile()` method of the Model class in `Keras`. This prepares the model for training and evaluation using the `fit()` and `evaluate()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nE_Llw2BvOBW"
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer=\"rmsprop\",\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the categorical loss functions in `Keras`:\n",
    "\n",
    "1. **CategoricalCrossentropy**: Computes the cross-entropy loss between true labels and predicted labels for multi-class classification problems. This loss function expects labels to be provided in a one-hot encoded format.\n",
    "2. **SparseCategoricalCrossentropy**: Similar to CategoricalCrossentropy, but can handle integer-encoded labels instead of one-hot encoded labels.\n",
    "3. **BinaryCrossentropy**: Computes the cross-entropy loss between true labels and predicted labels for binary classification problems. This loss function can be used when there are only two classes.\n",
    "4. **KLDivergence**: Computes the Kullback-Leibler divergence loss between true labels and predicted labels. This loss function is often used in generative models and can be used for multi-class classification problems.\n",
    "5. **Hinge**: Computes the hinge loss between true labels and predicted labels. This loss function is often used in support vector machines (SVMs) and can be used for multi-class classification problems.\n",
    "6. **SquaredHinge**: Computes the squared hinge loss between true labels and predicted labels. This loss function is a variant of the hinge loss and can be used for multi-class classification problems.\n",
    "\n",
    "Note that these loss functions can be used in combination with various optimizers in `Keras`, such as SGD, Adam, RMSprop, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtbaNXJVvOBW"
   },
   "source": [
    "## Input data preparation\n",
    "\n",
    "common practices for preparing input data for training and testing neural networks in Keras:\n",
    "\n",
    "1. **Data normalization**: Input data should be normalized to improve the convergence and stability of the training process. This can be done by scaling the data to have zero mean and unit variance or by rescaling the data to the range `[0, 1]` or `[-1, 1]`. Keras provides the preprocessing module to help with data normalization.\n",
    "\n",
    "2. **Data augmentation**: Data augmentation is a technique that involves creating new training samples by applying random transformations to the existing samples. This can improve the generalization ability of the model and reduce overfitting. Keras provides the `ImageDataGenerator` class to perform data augmentation on image data.\n",
    "\n",
    "3. **Data splitting**: Input data should be split into separate training, validation, and testing sets. The training set is used to train the model, the validation set is used to tune hyperparameters and monitor the training process, and the testing set is used to evaluate the final performance of the model. Keras provides the `train_test_split` function from the `model_selection` module to split data into training and testing sets.\n",
    "\n",
    "4. **Input shape**: The input shape of the data should be specified when creating the neural network model. The input shape is typically a tuple that specifies the dimensions of the input data, such as (height, width, channels) for image data or (sequence_length, num_features) for sequence data.\n",
    "\n",
    "5. **Data type**: Input data should be converted to the appropriate data type for the neural network model. Keras supports various data types, including float32, float64, int32, int64, etc.\n",
    "\n",
    "6. **Batching**: Input data should be divided into batches during training to speed up the training process and reduce memory usage. The **batch size** is a hyperparameter that can be tuned to balance the trade-off between training speed and model accuracy.\n",
    "\n",
    "These are some common practices for preparing input data in Keras. Depending on the specific problem and data, additional steps may be necessary, such as feature engineering or data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uXr1E4yvOBW"
   },
   "outputs": [],
   "source": [
    "train_images_1D = train_images.reshape((60000,28*28))\n",
    "train_images_1D = train_images_1D.astype(\"float32\")/255\n",
    "\n",
    "test_images_1D = test_images.reshape((10000,28*28))\n",
    "test_images_1D = test_images_1D.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMNin_XevOBX"
   },
   "source": [
    "## Label preparation\n",
    "\n",
    "The `to_categorical()` function in Keras is used to convert integer-encoded categorical labels into one-hot encoded categorical labels. This function is commonly used in multi-class classification problems where the target variable is represented by integer values.\n",
    "\n",
    "The function takes two arguments: `y` and `num_classes`. The **y** argument is the integer-encoded categorical labels and the **num_classes** argument is the total number of classes in the dataset.\n",
    "\n",
    "Here is an example of using `to_categorical()` in Keras:\n",
    "\n",
    "```\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Example integer-encoded categorical labels\n",
    "y_train = np.array([0, 1, 2, 0, 1, 2])\n",
    "\n",
    "# Convert integer labels to one-hot encoded labels\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
    "\n",
    "print(y_train_one_hot)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "array([[1., 0., 0.],\n",
    "       [0., 1., 0.],\n",
    "       [0., 0., 1.],\n",
    "       [1., 0., 0.],\n",
    "       [0., 1., 0.],\n",
    "       [0., 0., 1.]], dtype=float32)\n",
    "```\n",
    "\n",
    "In this example, the `y_train` variable contains integer-encoded categorical labels `[0, 1, 2, 0, 1, 2]` for a dataset with 3 classes. The `to_categorical()` function is used to convert these labels into one-hot encoded labels using `num_classes=3`. The resulting `y_train_one_hot` variable is a numpy array of shape `(6, 3)` where each row corresponds to a one-hot encoded label for the corresponding integer label in `y_train`.\n",
    "\n",
    "One-hot encoding is often used in multi-class classification problems as it allows the categorical labels to be represented as a vector of binary values, making it easier for the neural network model to learn the relationship between the inputs and the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdRDxXQvvOBX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09M6FODtvOBX"
   },
   "source": [
    "## Magic (fitting the model)\n",
    "\n",
    "The `fit()` method in Keras is used to train a neural network model on a given dataset. This method takes several arguments that control the training process, such as the **training data**, the **validation data**, the **loss function**, the **optimizer**, the **batch size**, the **number of epochs**, and more.\n",
    "\n",
    "Here is a brief explanation of how the `fit()` method works in Keras:\n",
    "\n",
    "1. **Input data preparation**: Before training the model, the input data should be prepared by normalizing, scaling, or augmenting it as needed. The input data should be split into separate training and validation sets.\n",
    "\n",
    "2. **Model compilation**: The model should be compiled using the `compile()` method before training. The compilation step sets the loss function, the optimizer, and the metrics to be used during training.\n",
    "\n",
    "3. **Model training**: The `fit()` method is called to train the model on the input data. The method takes the training and validation data as inputs, along with other hyperparameters such as the batch size and number of epochs.\n",
    "\n",
    "4. **Batching and epoch iteration**: During training, the input data is divided into batches of a fixed size (specified by the `batch_size` parameter). The model is trained on each batch, and the weights are updated based on the gradients calculated using backpropagation. After each epoch (defined by the epochs parameter), the entire training set is iterated over again.\n",
    "\n",
    "5. **Model evaluation**: After training, the model can be evaluated on a separate testing set using the `evaluate()` method. This method calculates the loss and metrics for the testing data and returns the results.\n",
    "\n",
    "Here is an example of using the `fit()` method in Keras:\n",
    "\n",
    "```\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val))\n",
    "```\n",
    "\n",
    "In this example, the `compile()` method is used to set the optimizer to adam, the loss function to `categorical_crossentropy`, and the metrics to accuracy. The `fit()` method is then called to train the model on the `x_train` and `y_train` datasets, using a batch size of 32 and training for 10 epochs. The `validation_data` parameter is used to specify the validation dataset.\n",
    "\n",
    "During training, the model is updated using the backpropagation algorithm, and the loss and accuracy are computed on both the training and validation data at the end of each epoch. After training, the model can be evaluated on a separate testing set using the `evaluate()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24363,
     "status": "ok",
     "timestamp": 1621346117778,
     "user": {
      "displayName": "Ian Postuma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYeRJeAxy1qvpQ_t5f1YoSP7a1UZO4qbynzAQ8=s64",
      "userId": "15420211039206829163"
     },
     "user_tz": -120
    },
    "id": "94b0-T0JvOBX",
    "outputId": "ad2271d5-7fc4-4ab5-ff97-b4d27612fb57"
   },
   "outputs": [],
   "source": [
    "network.fit(train_images_1D,\n",
    "            train_labels,\n",
    "            epochs=20,\n",
    "            batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8ndH8v9vOBY"
   },
   "source": [
    "## Test model\n",
    "\n",
    "The `evaluate()` method in Keras is used to evaluate the performance of a trained neural network model on a given dataset. Here is a brief explanation of how the `evaluate()` method works in Keras, assuming that the model has already been compiled and fitted:\n",
    "\n",
    "1. **Input data preparation**: Before evaluating the model, the input data should be prepared by normalizing, scaling, or augmenting it as needed. The input data should be split into separate testing and validation sets.\n",
    "\n",
    "2. **Model evaluation**: Once the model has been compiled and fitted, the `evaluate()` method is called to evaluate the model on the input data. The method takes the testing data as input, along with other hyperparameters such as the batch size.\n",
    "\n",
    "3. **Batching iteration**: During evaluation, the input data is divided into batches of a fixed size (specified by the `batch_size` parameter). The model is evaluated on each batch, and the loss and metrics are calculated for the entire testing set.\n",
    "\n",
    "4. **Evaluation results**: After evaluation, the `evaluate()` method returns the loss and metrics calculated for the testing set.\n",
    "\n",
    "Here is an example of using the `evaluate()` method in Keras, assuming that the model has already been compiled and fitted:\n",
    "\n",
    "```\n",
    "loss, accuracy = model.evaluate(x_test, y_test, batch_size=32)\n",
    "```\n",
    "\n",
    "In this example, the `evaluate()` method is called to evaluate the model on the `x_test` and `y_test` datasets, using a batch size of 32. Since the model has already been compiled and fitted, there is no need to specify the loss function, optimizer, or metrics.\n",
    "\n",
    "During evaluation, the model is evaluated on each batch of the testing data, and the loss and accuracy are computed for the entire testing set. After evaluation, the `evaluate()` method returns the loss and accuracy calculated for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23047,
     "status": "ok",
     "timestamp": 1621346118095,
     "user": {
      "displayName": "Ian Postuma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYeRJeAxy1qvpQ_t5f1YoSP7a1UZO4qbynzAQ8=s64",
      "userId": "15420211039206829163"
     },
     "user_tz": -120
    },
    "id": "175yoppSvOBY",
    "outputId": "b724b043-54ba-41a8-f8d8-9dca08e932f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images_1D,test_labels)\n",
    "print(\"loss = {}\\nAcc. = {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4lqIhX0vOBY"
   },
   "source": [
    "## Predict some data\n",
    "\n",
    "The `predict()` method in Keras is used to obtain the model's predictions for a given input data. This method takes the input data as input and returns the model's output predictions for that data. Here's a brief overview of how the `predict()` method works:\n",
    "\n",
    "1. **Input data preparation**: Before making predictions with the model, the input data should be prepared by normalizing, scaling, or augmenting it as needed.\n",
    "\n",
    "2. **Model prediction**: Once the input data is prepared, the `predict()` method is called on the model to obtain the predictions for the input data.\n",
    "\n",
    "3. **Batching iteration**: During prediction, the input data is divided into batches of a fixed size (specified by the `batch_size` parameter). The model makes predictions on each batch, and the output predictions are concatenated to obtain the final predictions for the entire input data.\n",
    "\n",
    "4. **Output predictions**: After prediction, the `predict()` method returns the output predictions for the input data.\n",
    "\n",
    "Here's an example of using the `predict()` method in Keras:\n",
    "\n",
    "```\n",
    "predictions = model.predict(x_test, batch_size=32)\n",
    "```\n",
    "\n",
    "In this example, the `predict()` method is called on the model to obtain predictions for the `x_test` dataset, using a batch size of 32.\n",
    "\n",
    "During prediction, the model makes predictions on each batch of the input data, and the output predictions are concatenated to obtain the final predictions for the entire input data. After prediction, the `predict()` method returns the output predictions for the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 21951,
     "status": "ok",
     "timestamp": 1621346118477,
     "user": {
      "displayName": "Ian Postuma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhYeRJeAxy1qvpQ_t5f1YoSP7a1UZO4qbynzAQ8=s64",
      "userId": "15420211039206829163"
     },
     "user_tz": -120
    },
    "id": "1dtnOzTHvOBZ",
    "outputId": "516ebfd5-9ba9-4303-931e-3a4cb993596f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y      = np.where(test_labels[0] == 1)[0][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(network.predict(test_images[0].reshape(1,28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(network.predict(test_images[0].reshape(1,28*28)))\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"y      = {}\\ny_pred = {}\".format(y,y_pred))\n",
    "plt.imshow(test_images[0],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLom0yRyvOBZ"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1) What is the shape of the input ?\n",
    "\n",
    "2) What is the shape of the output ?\n",
    "\n",
    "3) Define the predicted array as a 1D array containing the numeric prediction.\n",
    "\n",
    "4) Check and plot witch images the model doesn't predict correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDtkd-KrwVOS"
   },
   "outputs": [],
   "source": [
    "print(test_images.shape)\n",
    "y_pred = network.predict(test_images.reshape(10000,28*28))\n",
    "print(y_pred.shape)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "print(y_pred.shape)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbFk13GrwU8x"
   },
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    y = np.where(test_labels[i] == 1)[0][0]\n",
    "    if y != y_pred[i]:\n",
    "        plt.title(\"y      = {}\\ny_pred = {}\".format(y,y_pred[i]))\n",
    "        plt.imshow(test_images[i],cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S74EweMuwUXp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uxx_2RTgwUJm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions to questions 3 and 4 \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<details>\n",
    "  <summary>Answer Q.3</summary>\n",
    "    \n",
    "```\n",
    "    print(test_images.shape)\n",
    "    y_pred = network.predict(test_images.reshape(10000,28*28))\n",
    "    print(y_pred.shape)\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    print(y_pred.shape)\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>Answer Q.4</summary>\n",
    "  \n",
    "```\n",
    "for i in range(10000):\n",
    "    y = np.where(test_labels[i] == 1)[0][0]\n",
    "    if y != y_pred[i]:\n",
    "        plt.title(\"y      = {}\\ny_pred = {}\".format(y,y_pred[i]))\n",
    "        plt.imshow(test_images[i],cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MNIST_on_a_simple_Keras_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
